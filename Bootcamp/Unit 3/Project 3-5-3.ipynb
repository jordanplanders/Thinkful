{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boost guided example\n",
    "\n",
    "Having walked through gradient boost by hand, now let's try it with SKlearn.  We'll still use the European Social Survey Data, but now with a categorical outcome: Whether or not someone lives with a partner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()\n",
    "\n",
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = list(range(len(df2.happy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're now working with a binary outcome, we've switched to a classifier.  Now our loss function can't be the residuals.  Our options are \"deviance\", or \"exponential\".  Deviance is used for logistic regression, and we'll try that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04650845608292417\n",
      "Percent Type II errors: 0.17607746863066012\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06257668711656442\n",
      "Percent Type II errors: 0.18527607361963191\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike decision trees, gradient boost solutions are not terribly easy to interpret on the surface.  But they aren't quite a black box.  We can get a measure of how important various features are by counting how many times a feature is used over the course of many decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAEWCAYAAAAEtVmdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niriDOU6KuIM5Toq4gzlOiriDOU6K/B8YLsTYLki+HAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5cac390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that age and happiness are the most important features in predicting whether or not someone lives with a partner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### DRILL: Improve this gradient boost model\n",
    "\n",
    "While this model is already doing alright, we've seen from the Type I and Type II error rates that there is definitely room for improvement.  Your task is to see how low you can get the error rates to go in the test set, based on your model in the training set.  Strategies you might use include:\n",
    "\n",
    "* Creating new features\n",
    "* Applying more overfitting-prevention strategies like subsampling\n",
    "* More iterations\n",
    "* Trying a different loss function\n",
    "* Changing the structure of the weak learner: Allowing more leaves in the tree, or other modifications\n",
    "\n",
    "Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "df2 = pd.concat([df, pd.get_dummies(df['cntry'])], axis=1)\n",
    "df2['scandenavian'] = [1 if ctry in ['SE', 'DE', 'NO'] else 0 for ctry in df2['cntry']]\n",
    "df2['gndr'] = df2['gndr']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1995330>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD8CAYAAABgmUMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAFRRJREFUeJzt3X+w3XV95/Hny0REbDX8CJZNYm9o\nMyjL6MLeIlu7XVesBbGE7kgL4y5ZSpvdKV21tKPBdkq3HWdg6ooy7bKNkAquCyJayRZaNiKW3ZmC\nXMDyQ3TJYBauILldflZUGn3vH+dz12O4Sc43ueee++P5mDlzvp/P93PO9/3lm+TF9+dJVSFJ0qBe\nMuoCJEkLi8EhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUyfJRFzAMRxxxRI2N\njY26DElaUO66666/q6qV+xq3KINjbGyMiYmJUZchSQtKkv8zyDgPVUmSOjE4JEmdGBySpE4MDklS\nJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOlmUd45r4RjbdONIlrvj4tNGslxpMXCPQ5LUicEhSerE\n4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUiXeOCxjdHdySFh73OCRJnQwtOJJsSbIz\nyf0zzPvtJJXkiNZOksuSbE9yb5IT+sZuSPJQe20YVr2SpMEMc4/j48Apu3cmWQP8HPBIX/epwLr2\n2ghc3sYeBlwEvBE4EbgoyaFDrFmStA9DC46qug14coZZlwLvA6qvbz1wdfXcDqxIchTw88C2qnqy\nqp4CtjFDGEmS5s6cnuNIcjrwjar6291mrQIe7WtPtr499c/03RuTTCSZmJqamsWqJUn95iw4khwC\n/A7wezPNnqGv9tL/4s6qzVU1XlXjK1eu3P9CJUl7NZd7HD8BrAX+NskOYDVwd5Ifo7cnsaZv7Grg\nsb30S5JGZM6Co6ruq6ojq2qsqsbohcIJVfVNYCtwTru66iTgmap6HLgZeFuSQ9tJ8be1PknSiAzz\nctxrgL8BjkkymeS8vQy/CXgY2A58DPh1gKp6EvhD4M72+oPWJ0kakaHdOV5VZ+9j/ljfdAHn72Hc\nFmDLrBYnSdpv3jkuSerE4JAkdWJwSJI68em4WpJG+TTgHRefNrJlS7PBPQ5JUicGhySpE4NDktSJ\nwSFJ6sTgkCR1YnBIkjoxOCRJnRgckqRODA5JUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjoZ5m+O\nb0myM8n9fX1/lOSrSe5N8udJVvTNuzDJ9iRfS/Lzff2ntL7tSTYNq15J0mCGucfxceCU3fq2AcdV\n1euB/w1cCJDkWOAs4B+3z/znJMuSLAP+BDgVOBY4u42VJI3I0IKjqm4Dntyt739U1a7WvB1Y3abX\nA9dW1Xer6uvAduDE9tpeVQ9X1QvAtW2sJGlERnmO41eAv2zTq4BH++ZNtr499UuSRmQkwZHkd4Bd\nwCenu2YYVnvpn+k7NyaZSDIxNTU1O4VKkl5kzoMjyQbgHcC7qmo6BCaBNX3DVgOP7aX/Rapqc1WN\nV9X4ypUrZ79wSRIwx8GR5BTg/cDpVfV836ytwFlJXpZkLbAO+BJwJ7AuydokB9E7gb51LmuWJP2w\n5cP64iTXAG8GjkgyCVxE7yqqlwHbkgDcXlX/vqoeSHId8BV6h7DOr6rvte/5DeBmYBmwpaoeGFbN\nkqR9G1pwVNXZM3RfuZfxHwQ+OEP/TcBNs1iaJOkAeOe4JKkTg0OS1MnQDlUtZGObbhzJcndcfNpI\nlitJXbjHIUnqxOCQJHVicEiSOjE4JEmdeHJ8HhnVSXlJ6sI9DklSJwaHJKkTg0OS1InBIUnqxOCQ\nJHVicEiSOjE4JEmdGBySpE4MDklSJwaHJKmToQVHki1Jdia5v6/vsCTbkjzU3g9t/UlyWZLtSe5N\nckLfZza08Q8l2TCseiVJgxnmHsfHgVN269sE3FJV64BbWhvgVGBde20ELode0AAXAW8ETgQumg4b\nSdJoDO0hh1V1W5Kx3brXA29u01cBXwTe3/qvrqoCbk+yIslRbey2qnoSIMk2emF0zbDqlobNX5jU\nQjfX5zheXVWPA7T3I1v/KuDRvnGTrW9P/ZKkEZkvJ8czQ1/tpf/FX5BsTDKRZGJqampWi5Mk/cBc\nB8cT7RAU7X1n658E1vSNWw08tpf+F6mqzVU1XlXjK1eunPXCJUk9cx0cW4HpK6M2ADf09Z/Trq46\nCXimHcq6GXhbkkPbSfG3tT5J0ogM7eR4kmvondw+IskkvaujLgauS3Ie8AhwZht+E/B2YDvwPHAu\nQFU9meQPgTvbuD+YPlEuSRqNgYIjyXFVdf++R/5AVZ29h1knzzC2gPP38D1bgC1dli1JGp5BD1X9\nlyRfSvLrSVYMtSJJ0rw2UHBU1c8A76J3onoiyX9L8nNDrUySNC8NfHK8qh4CfpfeDXv/ArgsyVeT\n/KthFSdJmn8GCo4kr09yKfAg8BbgF6rqdW360iHWJ0maZwa9quqPgY8BH6iqb093VtVjSX53KJVJ\nkualQYPj7cC3q+p7AEleAhxcVc9X1SeGVp0kad4Z9BzH54GX97UPaX2SpCVm0OA4uKr+frrRpg8Z\nTkmSpPls0OD41m4/rvRPgW/vZbwkaZEa9BzHe4FPJ5l+wOBRwC8PpyRJ0nw2UHBU1Z1JXgscQ+9R\n51+tqn8YamWSpHmpy0MOfwoYa585PglVdfVQqpIkzVuDPuTwE8BPAF8Gvte6CzA4JGmJGXSPYxw4\ntj3FVpK0hA16VdX9wI8NsxBJ0sIw6B7HEcBXknwJ+O50Z1WdPpSqJEnz1qDB8fvDLEKStHAMejnu\nXyf5cWBdVX0+ySHAsuGWJkmajwZ9rPqvAdcDf9q6VgGfG1ZRkqT5a9CT4+cDbwKehf//o05H7u9C\nk/xmkgeS3J/kmiQHJ1mb5I4kDyX5VJKD2tiXtfb2Nn9sf5crSTpwgwbHd6vqhelGkuX07uPoLMkq\n4N3AeFUdR++Q11nAJcClVbUOeAo4r33kPOCpqvpJej8adcn+LFeSNDsGDY6/TvIB4OXtt8Y/Dfz3\nA1ju8vZdy+k9Zfdxer8meH2bfxVwRpte39q0+ScnyQEsW5J0AAYNjk3AFHAf8O+Am+j9/nhnVfUN\n4EPAI/QC4xngLuDpqtrVhk3SO49Ce3+0fXZXG3/47t+bZGOSiSQTU1NT+1OaJGkAg15V9X16Px37\nsQNdYJJD6e1FrAWeprf3cupMi53+yF7m9de4GdgMMD4+7h3ukjQkgz6r6uvM/I/10fuxzLcCX6+q\nqfbdnwV+GliRZHnbq1gNTD/CfRJYA0y2Q1uvAp7cj+VKkmZBl2dVTTsYOBM4bD+X+QhwUrsX5NvA\nycAEcCvwTuBaYANwQxu/tbX/ps3/gs/MkqTRGegcR1X9377XN6rqI/ROZndWVXfQO8l9N71zJi+h\nd4jp/cAFSbbTO4dxZfvIlcDhrf8CeudbJEkjMuihqhP6mi+htwfyo/u70Kq6CLhot+6HgRNnGPsd\nens4kqR5YNBDVf+pb3oXsAP4pVmvRpI07w16VdW/HHYhkqSFYdBDVRfsbX5VfXh2ypEkzXddrqr6\nKXpXOAH8AnAb7cY8SdLS0eWHnE6oqucAkvw+8Omq+tVhFSZJmp8GfeTIa4AX+tovAGOzXo0kad4b\ndI/jE8CXkvw5vTvIfxG4emhVSZLmrUGvqvpgkr8E/nnrOreq7hleWZKk+WrQQ1XQe/z5s1X1UXrP\njVo7pJokSfPYoD8dexG9R4Jc2LpeCvzXYRUlSZq/Bt3j+EXgdOBbAFX1GAfwyBFJ0sI1aHC80J5I\nWwBJXjG8kiRJ89mgwXFdkj+l95sZvwZ8nln4USdJ0sIz6FVVH2q/Nf4scAzwe1W1baiVSZLmpX0G\nR5JlwM1V9VbAsJCkJW6fh6qq6nvA80leNQf1SJLmuUHvHP8OcF+SbbQrqwCq6t1DqUqSNG8NGhw3\ntpckaYnba3AkeU1VPVJVV83mQpOsAK4AjqN3ie+vAF8DPkXv4Yk7gF+qqqeSBPgo8HbgeeDfVtXd\ns1mPJGlw+zrH8bnpiSSfmcXlfhT4q6p6LfAG4EFgE3BLVa0DbmltgFOBde21Ebh8FuuQJHW0r+BI\n3/TRs7HAJK8Efha4EqCqXqiqp4H1wPSezVXAGW16PXB19dxO716So2ajFklSd/sKjtrD9IE4GpgC\n/izJPUmuaHeiv7qqHgdo70e28av44V8anGx9kqQR2FdwvCHJs0meA17fpp9N8lySZ/dzmcuBE4DL\nq+p4eldpbdrL+MzQ96IQS7IxyUSSiampqf0sTZK0L3sNjqpaVlWvrKofrarlbXq6/cr9XOYkMFlV\nd7T29fSC5InpQ1DtfWff+DV9n18NPDZDrZuraryqxleuXLmfpUmS9qXL73HMiqr6JvBokmNa18nA\nV4CtwIbWtwG4oU1vBc5Jz0nAM9OHtCRJc2/Q+zhm238APpnkIOBh4Fx6IXZdkvOAR4Az29ib6F2K\nu53e5bjnzn25kqRpIwmOqvoyMD7DrJNnGFvA+UMvSpI0kDk/VCVJWtgMDklSJwaHJKkTg0OS1InB\nIUnqxOCQJHVicEiSOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHUyqt/jkDTHxjbd\nOLJl77j4tJEtW7PPPQ5JUicGhySpE4NDktTJyIIjybIk9yT5i9Zem+SOJA8l+VT7PXKSvKy1t7f5\nY6OqWZI02j2O9wAP9rUvAS6tqnXAU8B5rf884Kmq+kng0jZOkjQiIwmOJKuB04ArWjvAW4Dr25Cr\ngDPa9PrWps0/uY2XJI3AqPY4PgK8D/h+ax8OPF1Vu1p7EljVplcBjwK0+c+08ZKkEZjz4EjyDmBn\nVd3V3z3D0BpgXv/3bkwykWRiampqFiqVJM1kFHscbwJOT7IDuJbeIaqPACuSTN+QuBp4rE1PAmsA\n2vxXAU/u/qVVtbmqxqtqfOXKlcNdA0lawuY8OKrqwqpaXVVjwFnAF6rqXcCtwDvbsA3ADW16a2vT\n5n+hql60xyFJmhvz6T6O9wMXJNlO7xzGla3/SuDw1n8BsGlE9UmSGPGzqqrqi8AX2/TDwIkzjPkO\ncOacFiZJ2qP5tMchSVoADA5JUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjoxOCRJnRgckqRODA5J\nUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjoxOCRJnRgckqRODA5JUicGhySpkzkPjiRrktya5MEk\nDyR5T+s/LMm2JA+190Nbf5JclmR7knuTnDDXNUuSfmAUexy7gN+qqtcBJwHnJzkW2ATcUlXrgFta\nG+BUYF17bQQun/uSJUnT5jw4qurxqrq7TT8HPAisAtYDV7VhVwFntOn1wNXVczuwIslRc1y2JKkZ\n6TmOJGPA8cAdwKur6nHohQtwZBu2Cni072OTrW/379qYZCLJxNTU1DDLlqQlbWTBkeRHgM8A762q\nZ/c2dIa+elFH1eaqGq+q8ZUrV85WmZKk3YwkOJK8lF5ofLKqPtu6n5g+BNXed7b+SWBN38dXA4/N\nVa2SpB82iquqAlwJPFhVH+6btRXY0KY3ADf09Z/Trq46CXhm+pCWJGnuLR/BMt8E/BvgviRfbn0f\nAC4GrktyHvAIcGabdxPwdmA78Dxw7tyWK0nqN+fBUVX/i5nPWwCcPMP4As4falGSpIF557gkqROD\nQ5LUicEhSerE4JAkdWJwSJI6MTgkSZ2M4j4OSUvM2KYbR7LcHRefNpLlLnbucUiSOjE4JEmdGByS\npE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4WTHAkOSXJ15JsT7Jp1PVI\n0lK1IIIjyTLgT4BTgWOBs5McO9qqJGlpWhDBAZwIbK+qh6vqBeBaYP2Ia5KkJWmhPFZ9FfBoX3sS\neOOIapG0QIzqce6wuB/pvlCCIzP01Q8NSDYCG1vz75N8behVzewI4O9GtOxRWorrvRTXGZbmende\n51wypEqG68cHGbRQgmMSWNPXXg081j+gqjYDm+eyqJkkmaiq8VHXMdeW4novxXWGpbneS3Gd92ah\nnOO4E1iXZG2Sg4CzgK0jrkmSlqQFscdRVbuS/AZwM7AM2FJVD4y4LElakhZEcABU1U3ATaOuYwAj\nP1w2IktxvZfiOsPSXO+luM57lKra9yhJkpqFco5DkjRPGBz7KcmaJLcmeTDJA0ne0/oPS7ItyUPt\n/dBR1zoMSZYluSfJX7T22iR3tPX+VLuIYdFIsiLJ9Um+2rb5P1sK2zrJb7Y/3/cnuSbJwYtxWyfZ\nkmRnkvv7+mbcvum5rD3+6N4kJ4yu8tEwOPbfLuC3qup1wEnA+e0xKJuAW6pqHXBLay9G7wEe7Gtf\nAlza1vsp4LyRVDU8HwX+qqpeC7yB3rov6m2dZBXwbmC8qo6jd2HKWSzObf1x4JTd+va0fU8F1rXX\nRuDyOapx3jA49lNVPV5Vd7fp5+j9Q7KK3qNQrmrDrgLOGE2Fw5NkNXAacEVrB3gLcH0bsqjWO8kr\ngZ8FrgSoqheq6mmWwLamdwHNy5MsBw4BHmcRbuuqug14crfuPW3f9cDV1XM7sCLJUXNT6fxgcMyC\nJGPA8cAdwKur6nHohQtw5OgqG5qPAO8Dvt/ahwNPV9Wu1p6kF6KLxdHAFPBn7fDcFUlewSLf1lX1\nDeBDwCP0AuMZ4C4W97but6ftO9MjkBbrf4MZGRwHKMmPAJ8B3ltVz466nmFL8g5gZ1Xd1d89w9DF\ndLnecuAE4PKqOh74FovssNRM2jH99cBa4B8Br6B3mGZ3i2lbD2Kx/3nfJ4PjACR5Kb3Q+GRVfbZ1\nPzG929red46qviF5E3B6kh30nlL8Fnp7ICva4QyY4ZEwC9wkMFlVd7T29fSCZLFv67cCX6+qqar6\nB+CzwE+zuLd1vz1t330+AmmxMzj2UzuufyXwYFV9uG/WVmBDm94A3DDXtQ1TVV1YVauraozeidIv\nVNW7gFuBd7Zhi2q9q+qbwKNJjmldJwNfYZFva3qHqE5Kckj78z693ot2W+9mT9t3K3BOu7rqJOCZ\n6UNaS4U3AO6nJD8D/E/gPn5wrP8D9M5zXAe8ht5fvDOraveTbotCkjcDv11V70hyNL09kMOAe4B/\nXVXfHWV9synJP6F3McBBwMPAufT+x2tRb+sk/xH4ZXpXEd4D/Cq94/mLalsnuQZ4M72n4D4BXAR8\njhm2bwvRP6Z3FdbzwLlVNTGKukfF4JAkdeKhKklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4\nJEmdGBySpE7+H1fSEY9ZPD98AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x132596f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2.agea.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['sad_tv'] = [1 if ((df2['happy'][ind]<=6) & (df2['tvtot'][ind]>=3)) else 0 for ind in range(len(df2['happy']))]\n",
    "df2['happy_older_man'] = [1 if ((df2['happy'][ind]>=6) & (df2['gndr'][ind]==1) & (df2['agea'][ind]>60)) else 0 for ind in range(len(df2['happy']))]\n",
    "df2['happy_older_woman'] = [1 if ((df2['happy'][ind]>=6) & (df2['gndr'][ind]==0) & (df2['agea'][ind]>60)) else 0 for ind in range(len(df2['happy']))]\n",
    "df2['happy_older'] = [1 if ((df2['happy'][ind]>=6) & (df2['agea'][ind]>60)) else 0 for ind in range(len(df2['happy']))]\n",
    "df2['happy_young_man'] = [1 if ((df2['happy'][ind]>=6) & (df2['gndr'][ind]==1) & (df2['agea'][ind]<30)) else 0 for ind in range(len(df2['happy']))]\n",
    "df2['happy_young_woman'] = [1 if ((df2['happy'][ind]>=6) & (df2['gndr'][ind]==0) & (df2['agea'][ind]<30)) else 0 for ind in range(len(df2['happy']))]\n",
    "df2['older_man'] = [1 if ((df2['gndr'][ind]==1) & (df2['agea'][ind]>60)) else 0 for ind in range(len(df2['happy']))]\n",
    "df2['older_woman'] = [1 if ((df2['gndr'][ind]==0) & (df2['agea'][ind]>60)) else 0 for ind in range(len(df2['happy']))]\n",
    "df2['young_woman'] = [1 if ((df2['gndr'][ind]==0) & (df2['agea'][ind]<30)) else 0 for ind in range(len(df2['happy']))]\n",
    "df2['young_man'] = [1 if ((df2['gndr'][ind]==1) & (df2['agea'][ind]<30)) else 0 for ind in range(len(df2['happy']))]\n",
    "df2['hapy_trst'] = df2['happy']*df2['ppltrst']\n",
    "df2['trst_fair'] = df2['ppltrst']*df2['pplfair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.loc[:, ~df2.columns.isin(['SE', 'DE', 'NO', 'cntry', 'idno', 'partner'])]\n",
    "Y = df2['partner']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=2,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0, n_estimators=400, presort='auto',\n",
       "              random_state=None, subsample=0.9, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 400,\n",
    "          'max_depth': 2,\n",
    "          'min_weight_fraction_leaf': 0,\n",
    "          'loss': 'deviance',\n",
    "          'subsample': .9}\n",
    "\n",
    "#parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "#>>> svc = svm.SVC(gamma=\"scale\")\n",
    "#>>> clf = GridSearchCV(svc, parameters, cv=5)\n",
    "#>>> clf.fit(iris.data, iris.target)\n",
    "#\n",
    "# GradientBoostingClassifier(loss=’deviance’, learning_rate=0.1, n_estimators=100, subsample=1.0, \n",
    "# criterion=’friedman_mse’, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "# max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, \n",
    "# max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort=’auto’, validation_fraction=0.1, \n",
    "# n_iter_no_change=None, tol=0.0001)\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf2 = ensemble.GradientBoostingClassifier(**params)\n",
    "\n",
    "clf2.fit(scaler.transform(X_train), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.044844517184942714\n",
      "Percent Type II errors: 0.17054009819967267\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.058419243986254296\n",
      "Percent Type II errors: 0.19293078055964655\n"
     ]
    }
   ],
   "source": [
    "predict_train = clf2.predict(scaler.transform(X_train))\n",
    "predict_test = clf2.predict(scaler.transform(X_test))\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR0AAAEWCAYAAABbrUO4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19951b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf2.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Run Parameter grid search to find optimal parameter set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss=['deviance', 'exponential'],\n",
       "              max_depth=[2, 3], max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_sam...              random_state=None, subsample=[0.8, 0.9, 1], verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [400, 500, 600], 'max_depth': [2, 3], 'min_weight_fraction_leaf': [0, 0.1, 0.2, 0.5], 'loss': ['deviance', 'exponential'], 'subsample': [0.8, 0.9, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': list(range(400,700,100)),\n",
    "          'max_depth': [2,3],\n",
    "          'min_weight_fraction_leaf': [0,.1,.2,.5],\n",
    "          'loss': ['deviance','exponential'],\n",
    "          'subsample': [.8, .9,1]}\n",
    "\n",
    "#parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "#>>> svc = svm.SVC(gamma=\"scale\")\n",
    "#>>> clf = GridSearchCV(svc, parameters, cv=5)\n",
    "#>>> clf.fit(iris.data, iris.target)\n",
    "#\n",
    "# GradientBoostingClassifier(loss=’deviance’, learning_rate=0.1, n_estimators=100, subsample=1.0, \n",
    "# criterion=’friedman_mse’, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "# max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, \n",
    "# max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort=’auto’, validation_fraction=0.1, \n",
    "# n_iter_no_change=None, tol=0.0001)\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf2 = ensemble.GradientBoostingClassifier(**params)\n",
    "clf = GridSearchCV(clf2, params, cv=5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='exponential', max_depth=2,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0, n_estimators=400, presort='auto',\n",
      "              random_state=None, subsample=0.8, verbose=0,\n",
      "              warm_start=False)\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.757 (+/-0.005) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 400, 'subsample': 0.8}\n",
      "0.757 (+/-0.004) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 400, 'subsample': 0.9}\n",
      "0.755 (+/-0.005) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 400, 'subsample': 1}\n",
      "0.753 (+/-0.005) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.758 (+/-0.005) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 500, 'subsample': 0.9}\n",
      "0.754 (+/-0.004) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 500, 'subsample': 1}\n",
      "0.755 (+/-0.004) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 600, 'subsample': 0.8}\n",
      "0.754 (+/-0.004) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 600, 'subsample': 0.9}\n",
      "0.754 (+/-0.005) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 600, 'subsample': 1}\n",
      "0.756 (+/-0.006) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 400, 'subsample': 0.8}\n",
      "0.753 (+/-0.006) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 400, 'subsample': 0.9}\n",
      "0.751 (+/-0.006) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 400, 'subsample': 1}\n",
      "0.755 (+/-0.005) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.755 (+/-0.004) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 500, 'subsample': 0.9}\n",
      "0.753 (+/-0.006) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 500, 'subsample': 1}\n",
      "0.755 (+/-0.005) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 600, 'subsample': 0.8}\n",
      "0.754 (+/-0.003) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 600, 'subsample': 0.9}\n",
      "0.754 (+/-0.006) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 600, 'subsample': 1}\n",
      "0.738 (+/-0.005) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 400, 'subsample': 0.8}\n",
      "0.737 (+/-0.005) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 400, 'subsample': 0.9}\n",
      "0.739 (+/-0.004) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 400, 'subsample': 1}\n",
      "0.739 (+/-0.004) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.736 (+/-0.003) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 500, 'subsample': 0.9}\n",
      "0.739 (+/-0.004) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 500, 'subsample': 1}\n",
      "0.734 (+/-0.006) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 600, 'subsample': 0.8}\n",
      "0.736 (+/-0.004) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 600, 'subsample': 0.9}\n",
      "0.738 (+/-0.004) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 600, 'subsample': 1}\n",
      "0.619 (+/-0.000) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 400, 'subsample': 0.8}\n",
      "0.619 (+/-0.000) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 400, 'subsample': 0.9}\n",
      "0.619 (+/-0.000) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 400, 'subsample': 1}\n",
      "0.619 (+/-0.000) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.619 (+/-0.000) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 500, 'subsample': 0.9}\n",
      "0.619 (+/-0.000) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 500, 'subsample': 1}\n",
      "0.619 (+/-0.000) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 600, 'subsample': 0.8}\n",
      "0.619 (+/-0.000) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 600, 'subsample': 0.9}\n",
      "0.619 (+/-0.000) for {'loss': 'deviance', 'max_depth': 2, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 600, 'subsample': 1}\n",
      "0.749 (+/-0.005) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0, 'n_estimators': 400, 'subsample': 0.8}\n",
      "0.749 (+/-0.004) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0, 'n_estimators': 400, 'subsample': 0.9}\n",
      "0.754 (+/-0.004) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0, 'n_estimators': 400, 'subsample': 1}\n",
      "0.749 (+/-0.004) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.753 (+/-0.005) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0, 'n_estimators': 500, 'subsample': 0.9}\n",
      "0.748 (+/-0.005) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0, 'n_estimators': 500, 'subsample': 1}\n",
      "0.746 (+/-0.006) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0, 'n_estimators': 600, 'subsample': 0.8}\n",
      "0.750 (+/-0.004) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0, 'n_estimators': 600, 'subsample': 0.9}\n",
      "0.745 (+/-0.003) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0, 'n_estimators': 600, 'subsample': 1}\n",
      "0.752 (+/-0.005) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 400, 'subsample': 0.8}\n",
      "0.754 (+/-0.003) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 400, 'subsample': 0.9}\n",
      "0.754 (+/-0.004) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 400, 'subsample': 1}\n",
      "0.752 (+/-0.004) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.754 (+/-0.004) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 500, 'subsample': 0.9}\n",
      "0.753 (+/-0.004) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 500, 'subsample': 1}\n",
      "0.753 (+/-0.005) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 600, 'subsample': 0.8}\n",
      "0.750 (+/-0.004) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 600, 'subsample': 0.9}\n",
      "0.754 (+/-0.005) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 600, 'subsample': 1}\n",
      "0.739 (+/-0.005) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 400, 'subsample': 0.8}\n",
      "0.737 (+/-0.004) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 400, 'subsample': 0.9}\n",
      "0.740 (+/-0.004) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 400, 'subsample': 1}\n",
      "0.737 (+/-0.005) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.737 (+/-0.004) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 500, 'subsample': 0.9}\n",
      "0.740 (+/-0.003) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 500, 'subsample': 1}\n",
      "0.739 (+/-0.005) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 600, 'subsample': 0.8}\n",
      "0.736 (+/-0.005) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 600, 'subsample': 0.9}\n",
      "0.738 (+/-0.004) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 600, 'subsample': 1}\n",
      "0.619 (+/-0.000) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 400, 'subsample': 0.8}\n",
      "0.619 (+/-0.000) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 400, 'subsample': 0.9}\n",
      "0.619 (+/-0.000) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 400, 'subsample': 1}\n",
      "0.619 (+/-0.000) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.619 (+/-0.000) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 500, 'subsample': 0.9}\n",
      "0.619 (+/-0.000) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 500, 'subsample': 1}\n",
      "0.619 (+/-0.000) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 600, 'subsample': 0.8}\n",
      "0.619 (+/-0.000) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 600, 'subsample': 0.9}\n",
      "0.619 (+/-0.000) for {'loss': 'deviance', 'max_depth': 3, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 600, 'subsample': 1}\n",
      "0.759 (+/-0.004) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 400, 'subsample': 0.8}\n",
      "0.756 (+/-0.005) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 400, 'subsample': 0.9}\n",
      "0.757 (+/-0.003) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 400, 'subsample': 1}\n",
      "0.756 (+/-0.005) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.756 (+/-0.004) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 500, 'subsample': 0.9}\n",
      "0.756 (+/-0.004) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 500, 'subsample': 1}\n",
      "0.755 (+/-0.005) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 600, 'subsample': 0.8}\n",
      "0.755 (+/-0.004) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 600, 'subsample': 0.9}\n",
      "0.756 (+/-0.004) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0, 'n_estimators': 600, 'subsample': 1}\n",
      "0.753 (+/-0.005) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 400, 'subsample': 0.8}\n",
      "0.751 (+/-0.005) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 400, 'subsample': 0.9}\n",
      "0.751 (+/-0.005) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 400, 'subsample': 1}\n",
      "0.752 (+/-0.004) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.754 (+/-0.004) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 500, 'subsample': 0.9}\n",
      "0.750 (+/-0.005) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 500, 'subsample': 1}\n",
      "0.752 (+/-0.004) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 600, 'subsample': 0.8}\n",
      "0.753 (+/-0.005) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 600, 'subsample': 0.9}\n",
      "0.750 (+/-0.006) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 600, 'subsample': 1}\n",
      "0.739 (+/-0.005) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 400, 'subsample': 0.8}\n",
      "0.737 (+/-0.004) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 400, 'subsample': 0.9}\n",
      "0.740 (+/-0.004) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 400, 'subsample': 1}\n",
      "0.737 (+/-0.006) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.739 (+/-0.004) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 500, 'subsample': 0.9}\n",
      "0.739 (+/-0.004) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 500, 'subsample': 1}\n",
      "0.737 (+/-0.005) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 600, 'subsample': 0.8}\n",
      "0.737 (+/-0.004) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 600, 'subsample': 0.9}\n",
      "0.738 (+/-0.004) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 600, 'subsample': 1}\n",
      "0.619 (+/-0.000) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 400, 'subsample': 0.8}\n",
      "0.619 (+/-0.000) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 400, 'subsample': 0.9}\n",
      "0.619 (+/-0.000) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 400, 'subsample': 1}\n",
      "0.619 (+/-0.000) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.619 (+/-0.000) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 500, 'subsample': 0.9}\n",
      "0.619 (+/-0.000) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 500, 'subsample': 1}\n",
      "0.619 (+/-0.000) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 600, 'subsample': 0.8}\n",
      "0.619 (+/-0.000) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 600, 'subsample': 0.9}\n",
      "0.619 (+/-0.000) for {'loss': 'exponential', 'max_depth': 2, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 600, 'subsample': 1}\n",
      "0.751 (+/-0.005) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0, 'n_estimators': 400, 'subsample': 0.8}\n",
      "0.753 (+/-0.005) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0, 'n_estimators': 400, 'subsample': 0.9}\n",
      "0.750 (+/-0.004) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0, 'n_estimators': 400, 'subsample': 1}\n",
      "0.750 (+/-0.005) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.749 (+/-0.005) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0, 'n_estimators': 500, 'subsample': 0.9}\n",
      "0.749 (+/-0.004) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0, 'n_estimators': 500, 'subsample': 1}\n",
      "0.745 (+/-0.005) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0, 'n_estimators': 600, 'subsample': 0.8}\n",
      "0.748 (+/-0.003) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0, 'n_estimators': 600, 'subsample': 0.9}\n",
      "0.751 (+/-0.004) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0, 'n_estimators': 600, 'subsample': 1}\n",
      "0.751 (+/-0.005) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 400, 'subsample': 0.8}\n",
      "0.753 (+/-0.004) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 400, 'subsample': 0.9}\n",
      "0.753 (+/-0.004) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 400, 'subsample': 1}\n",
      "0.751 (+/-0.004) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.752 (+/-0.003) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 500, 'subsample': 0.9}\n",
      "0.754 (+/-0.004) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 500, 'subsample': 1}\n",
      "0.750 (+/-0.005) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 600, 'subsample': 0.8}\n",
      "0.751 (+/-0.005) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 600, 'subsample': 0.9}\n",
      "0.751 (+/-0.004) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.1, 'n_estimators': 600, 'subsample': 1}\n",
      "0.737 (+/-0.005) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 400, 'subsample': 0.8}\n",
      "0.739 (+/-0.005) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 400, 'subsample': 0.9}\n",
      "0.738 (+/-0.004) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 400, 'subsample': 1}\n",
      "0.736 (+/-0.006) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.739 (+/-0.005) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 500, 'subsample': 0.9}\n",
      "0.737 (+/-0.004) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 500, 'subsample': 1}\n",
      "0.738 (+/-0.005) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 600, 'subsample': 0.8}\n",
      "0.737 (+/-0.005) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 600, 'subsample': 0.9}\n",
      "0.736 (+/-0.004) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.2, 'n_estimators': 600, 'subsample': 1}\n",
      "0.619 (+/-0.000) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 400, 'subsample': 0.8}\n",
      "0.619 (+/-0.000) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 400, 'subsample': 0.9}\n",
      "0.619 (+/-0.000) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 400, 'subsample': 1}\n",
      "0.619 (+/-0.000) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 500, 'subsample': 0.8}\n",
      "0.619 (+/-0.000) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 500, 'subsample': 0.9}\n",
      "0.619 (+/-0.000) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 500, 'subsample': 1}\n",
      "0.619 (+/-0.000) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 600, 'subsample': 0.8}\n",
      "0.619 (+/-0.000) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 600, 'subsample': 0.9}\n",
      "0.619 (+/-0.000) for {'loss': 'exponential', 'max_depth': 3, 'min_weight_fraction_leaf': 0.5, 'n_estimators': 600, 'subsample': 1}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jordan landers\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_estimator_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "for params, mean_score, scores in clf.grid_scores_:\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() / 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "#print(classification_report(y_true, y_pred))\n",
    "#print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0469721767594108\n",
      "Percent Type II errors: 0.17201309328968903\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.058419243986254296\n",
      "Percent Type II errors: 0.19145802650957292\n"
     ]
    }
   ],
   "source": [
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "59px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
