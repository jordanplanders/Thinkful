{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " https://www.npr.org/people/1936301/john-burnett/archive\n",
      "\n",
      " https://www.npr.org/people/348780034/nicole-cohen/archive\n",
      "\n",
      " https://www.npr.org/people/2100689/christopher-joyce/archive\n",
      "\n",
      " https://www.npr.org/people/384067907/rebecca-hersher/archive\n",
      "\n",
      " https://www.npr.org/people/2100615/jon-hamilton/archive\n",
      "\n",
      " https://www.npr.org/people/468930062/jane-greenhalgh/archive\n",
      "\n",
      " https://www.npr.org/people/536711382/gisele-grayson/archive\n",
      "\n",
      " https://www.npr.org/people/348732739/adam-cole/archive\n",
      "\n",
      " https://www.npr.org/people/578890280/rhitu-chatterjee/archive\n",
      "\n",
      " https://www.npr.org/people/1931801/linda-wertheimer/archive\n",
      "\n",
      " https://www.npr.org/people/2101212/lakshmi-singh/archive\n",
      "\n",
      " https://www.npr.org/people/348730771/aarti-shahani/archive\n",
      "\n",
      " https://www.npr.org/people/676406186/sacha-pfeiffer/archive\n",
      "\n",
      " https://www.npr.org/people/96022165/yuki-noguchi/archive\n",
      "\n",
      " https://www.npr.org/people/131724812/scott-neuman/archive\n",
      "\n",
      " https://www.npr.org/people/467974737/brett-neely/archive\n",
      "\n",
      " https://www.npr.org/people/2100955/patti-neighmond/archive\n",
      "442\n",
      "5\n",
      "404\n",
      "89\n",
      "364\n",
      "20\n",
      "6\n",
      "30\n",
      "32\n",
      "323\n",
      "29\n",
      "199\n",
      "0\n",
      "447\n",
      "14\n",
      "5\n",
      "256\n",
      "\n",
      " https://www.npr.org/people/392602474/domenico-montanaro/archive\n",
      "\n",
      " https://www.npr.org/people/448294256/sarah-mccammon/archive\n",
      "\n",
      " https://www.npr.org/people/2100815/jennifer-ludden/archive\n",
      "\n",
      " https://www.npr.org/people/122805042/tamara-keith/archive\n",
      "\n",
      " https://www.npr.org/people/384067907/rebecca-hersher/archive\n",
      "\n",
      " https://www.npr.org/people/2100615/jon-hamilton/archive\n",
      "\n",
      " https://www.npr.org/people/2100569/richard-gonzales/archive\n",
      "\n",
      " https://www.npr.org/people/349241810/rose-friedman/archive\n",
      "\n",
      " https://www.npr.org/people/1930203/ron-elving/archive\n",
      "\n",
      " https://www.npr.org/people/2100438/debbie-elliott/archive\n",
      "\n",
      " https://www.npr.org/people/348778932/michaeleen-doucleff/archive\n",
      "156\n",
      "238\n",
      "342\n",
      "705\n",
      "305\n",
      "14\n",
      "280\n",
      "402\n",
      "85\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# from scrapy.contrib.spiders import CrawlSpider\n",
    "from selenium import webdriver\n",
    "\n",
    "from scrapy.http import Request\n",
    "from scrapy import Selector\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import scrapy\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "class NPRSpider(scrapy.Spider):\n",
    "    name = 'npr-spider'\n",
    "    allowed_domains = ['www.npr.org']\n",
    "\n",
    "    def start_requests(self):\n",
    "        urls = ['https://www.npr.org/people/1936301/john-burnett/archive',\n",
    "               'https://www.npr.org/people/348780034/nicole-cohen/archive',\n",
    "               'https://www.npr.org/people/2100689/christopher-joyce/archive',\n",
    "               'https://www.npr.org/people/384067907/rebecca-hersher/archive',\n",
    "               'https://www.npr.org/people/2100615/jon-hamilton/archive',\n",
    "               'https://www.npr.org/people/468930062/jane-greenhalgh/archive',\n",
    "               'https://www.npr.org/people/536711382/gisele-grayson/archive',\n",
    "               'https://www.npr.org/people/348732739/adam-cole/archive',\n",
    "               'https://www.npr.org/people/578890280/rhitu-chatterjee/archive',\n",
    "               'https://www.npr.org/people/1931801/linda-wertheimer/archive',\n",
    "               'https://www.npr.org/people/2101212/lakshmi-singh/archive',\n",
    "               'https://www.npr.org/people/348730771/aarti-shahani/archive',\n",
    "               'https://www.npr.org/people/676406186/sacha-pfeiffer/archive',\n",
    "               'https://www.npr.org/people/96022165/yuki-noguchi/archive',\n",
    "               'https://www.npr.org/people/131724812/scott-neuman/archive',\n",
    "               'https://www.npr.org/people/467974737/brett-neely/archive',\n",
    "               'https://www.npr.org/people/2100955/patti-neighmond/archive',\n",
    "               'https://www.npr.org/people/392602474/domenico-montanaro/archive',\n",
    "               'https://www.npr.org/people/448294256/sarah-mccammon/archive',\n",
    "               'https://www.npr.org/people/2100815/jennifer-ludden/archive',\n",
    "               'https://www.npr.org/people/122805042/tamara-keith/archive',\n",
    "               'https://www.npr.org/people/384067907/rebecca-hersher/archive',\n",
    "               'https://www.npr.org/people/2100615/jon-hamilton/archive',\n",
    "               'https://www.npr.org/people/2100569/richard-gonzales/archive',\n",
    "               'https://www.npr.org/people/349241810/rose-friedman/archive',\n",
    "               'https://www.npr.org/people/1930203/ron-elving/archive',\n",
    "               'https://www.npr.org/people/2100438/debbie-elliott/archive',\n",
    "               'https://www.npr.org/people/348778932/michaeleen-doucleff/archive'\n",
    "               ]\n",
    "#         'https://www.npr.org/people/7569853/russell-lewis/archive',\n",
    "#                 'https://www.npr.org/people/2101154/ari-shapiro/archive',\n",
    "#                 'https://www.npr.org/people/5201175/michel-martin/archive',\n",
    "#                 'https://www.npr.org/people/348766539/greg-myre/archive',\n",
    "#                 'https://www.npr.org/people/473143808/alison-kodjak/archive', \n",
    "#                 'https://www.npr.org/people/2788801/scott-horsley/archive',\n",
    "#                 'https://www.npr.org/people/5201175/michel-martin/archive',\n",
    "#                 'https://www.npr.org/people/2100631/richard-harris/archive',\n",
    "#                 'https://www.npr.org/people/2101154/ari-shapiro/archive',\n",
    "#                 'https://www.npr.org/people/146944972/rob-stein/archive',\n",
    "#                 'https://www.npr.org/people/544275644/ryan-lucas/archive',\n",
    "#                 'https://www.npr.org/people/2101062/philip-reeves/archive',\n",
    "#                 'https://www.npr.org/people/279612138/geoff-brumfiel/archive',\n",
    "        \n",
    "        for start_url in urls:\n",
    "            print('\\n',start_url)\n",
    "            yield Request(url = start_url, callback=self.parsencmilllist)\n",
    "\n",
    "    def parsencmilllist(self, response):\n",
    "        driver = webdriver.Chrome(executable_path='./chromedriver')\n",
    "        driver.get(response.url)\n",
    "        time.sleep(4)\n",
    "        \n",
    "        for i in range(1,60):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(4)\n",
    "        sel = Selector(text=driver.page_source)\n",
    "\n",
    "        links = sel.xpath('//li[@class = \"audio-tool audio-tool-transcript\"]//a/@href').extract()\n",
    "        print(len(links))\n",
    "        for link in links:\n",
    "            yield Request(link,\n",
    "                          meta={'type': 'Milling'},\n",
    "                          callback=self.parsencmachine)\n",
    "\n",
    "    def parsencmachine(self, response):\n",
    "            \n",
    "        for article in [response.xpath('//article[@class=\"story\"]')]:\n",
    "#             print(article.xpath('//div[@class=\"storytitle\"]/h1[@class = \"transcript\"]/a/text()').extract())\n",
    "            yield {\n",
    "                    'text': article.xpath('//div[@class=\"transcript storytext\"]').extract(),#.xpath('a/@href').extract(),\n",
    "                    'title': article.xpath('//div[@class=\"storytitle\"]/h1[@class = \"transcript\"]/a/text()').extract(),\n",
    "                                }\n",
    "\n",
    "process = CrawlerProcess({\n",
    "    'FEED_FORMAT': 'json',         # Store data in JSON format.\n",
    "    'FEED_URI': 'npr_url_text2.json',       # Name our storage file.\n",
    "    'LOG_ENABLED': False,          # Turn off logging for now.\n",
    "    'ROBOTSTXT_OBEY': True,\n",
    "    'USER_AGENT': 'ThinkfulDataScienceBootcampCrawler (thinkful.com)',\n",
    "    'AUTOTHROTTLE_ENABLED': True,\n",
    "    'HTTPCACHE_ENABLED': True\n",
    "})\n",
    "\n",
    "# Start the crawler with our spider.\n",
    "process.crawl(NPRSpider)\n",
    "process.start()\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "from gensim.models import Doc2Vec\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_curve,auc, silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "from IPython.display import set_matplotlib_formats\n",
    "%matplotlib inline\n",
    "set_matplotlib_formats('svg')\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import itertools\n",
    "\n",
    "from itertools import combinations\n",
    "import csv\n",
    "\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "npr_raw = pd.read_json('npr_url_text2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_text = []\n",
    "titles_tmp = []\n",
    "story_raw = []\n",
    "for ik in range(len(npr_raw)): \n",
    "    try:\n",
    "        txt = (npr_raw.text[ik][0].split('</b>\\n\\n    <p>')[1]).split('</p>\\n\\n    <p class=\"disclaimer\">C')[0]\n",
    "        story_text.append(' '.join(txt.split('</p>\\n    <p>',1)))\n",
    "        titles_tmp.append(npr_raw.iloc[ik]['title'][0])\n",
    "        story_raw.append(npr_raw.text[ik][0])\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr_raw2 = pd.DataFrame({'title':titles_tmp, 'text':story_text, 'raw_text':story_raw})\n",
    "\n",
    "npr_raw2= npr_raw2.drop_duplicates()\n",
    "npr_raw2 = npr_raw2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NPR correspondent/reporter archive links\n",
    "urls = [\n",
    "    'https://www.npr.org/people/1931801/linda-wertheimer/archive',\n",
    "    'https://www.npr.org/people/2101212/lakshmi-singh/archive',\n",
    "    'https://www.npr.org/people/467974737/brett-neely/archive',\n",
    "    'https://www.npr.org/people/2100955/patti-neighmond/archive',\n",
    "    'https://www.npr.org/people/392602474/domenico-montanaro/archive',\n",
    "    'https://www.npr.org/people/1936301/john-burnett/archive',\n",
    "    'https://www.npr.org/people/348780034/nicole-cohen/archive',\n",
    "    'https://www.npr.org/people/349241810/rose-friedman/archive',\n",
    "        \n",
    "    'https://www.npr.org/people/2100689/christopher-joyce/archive',\n",
    "    'https://www.npr.org/people/384067907/rebecca-hersher/archive',\n",
    "         \n",
    "   'https://www.npr.org/people/468930062/jane-greenhalgh/archive',\n",
    "\n",
    "   'https://www.npr.org/people/536711382/gisele-grayson/archive',\n",
    "   'https://www.npr.org/people/578890280/rhitu-chatterjee/archive',\n",
    "\n",
    "   'https://www.npr.org/people/348730771/aarti-shahani/archive',\n",
    "   'https://www.npr.org/people/676406186/sacha-pfeiffer/archive',\n",
    "   'https://www.npr.org/people/96022165/yuki-noguchi/archive',\n",
    "   'https://www.npr.org/people/131724812/scott-neuman/archive',\n",
    "\n",
    "   'https://www.npr.org/people/448294256/sarah-mccammon/archive',\n",
    "   'https://www.npr.org/people/2100815/jennifer-ludden/archive',\n",
    "   'https://www.npr.org/people/122805042/tamara-keith/archive',\n",
    "   'https://www.npr.org/people/2100569/richard-gonzales/archive',\n",
    "\n",
    "    'https://www.npr.org/people/5201175/michel-martin/archive',\n",
    "    'https://www.npr.org/people/2100615/jon-hamilton/archive',\n",
    "    'https://www.npr.org/people/2101154/ari-shapiro/archive'\n",
    "    'https://www.npr.org/people/2100438/debbie-elliott/archive',\n",
    "    'https://www.npr.org/people/348778932/michaeleen-doucleff/archive',\n",
    "    'https://www.npr.org/people/7569853/russell-lewis/archive',\n",
    "    'https://www.npr.org/people/348766539/greg-myre/archive',\n",
    "    'https://www.npr.org/people/473143808/alison-kodjak/archive', \n",
    "    'https://www.npr.org/people/2788801/scott-horsley/archive',\n",
    "    'https://www.npr.org/people/2100631/richard-harris/archive',\n",
    "    'https://www.npr.org/people/146944972/rob-stein/archive',\n",
    "    'https://www.npr.org/people/544275644/ryan-lucas/archive',\n",
    "    'https://www.npr.org/people/2101062/philip-reeves/archive',\n",
    "    'https://www.npr.org/people/279612138/geoff-brumfiel/archive',\n",
    "    'https://www.npr.org/people/1930203/ron-elving/archive',\n",
    "    'https://www.npr.org/people/2100569/richard-gonzales/archive']\n",
    "\n",
    "names = []\n",
    "for url in urls:\n",
    "    names.append(url.split('/')[5].replace('-', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_npr_text(story, title):\n",
    "\n",
    "    speakers = []\n",
    "    comments = []\n",
    "    d = {'host': '', 'byline': ''}\n",
    "    \n",
    "    story = re.sub(r'([A-Z])-([A-Z])', r'\\1\\2', story)\n",
    "    story = re.sub(r'([A-Z])\\'([A-Z])', r'\\1\\2', story)\n",
    "    \n",
    "    story = re.sub(r'(</p>\\n    <p>)([A-Z]{4})', r'\\1</p>\\n    <p> \\2',  story)\n",
    "    story = re.sub(r'(</p>\\n    <p>)\\(([A-Z]{4})', r'\\1</p>\\n    <p> \\2',  story)\n",
    "    story = re.sub(r'(</p>\\n    <p>)(.*?)(:)', r'\\1</p>\\n    <p> \\2\\3',  story)\n",
    "    \n",
    "    lines = story.split('</p>\\n    <p></p>\\n    <p> ')\n",
    "    lines = [line.replace('</p>\\n    <p>', ' ') for line in lines ]\n",
    "    \n",
    "    for ik, line in enumerate(lines):\n",
    "        if 'SOUNDBITE' not in line:\n",
    "            try:\n",
    "                [speaker, comment] = line.split(':', 1)\n",
    "                for label in [['HOST', 'host'],['BYLINE', 'byline'] ]:\n",
    "                    if len(speaker.split(label[0]))>1:\n",
    "                        speaker = speaker.split(label[0])[0].strip(', ').split(' ')[-1]\n",
    "                        d[label[1]] = speaker\n",
    "\n",
    "                speakers.append(speaker.strip())\n",
    "                for name in names: \n",
    "                    comment = comment.lower().replace(name, ' ')\n",
    "                comments.append(comment)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    host_cs = [1 if speaker == d['host'] else 0 for speaker in speakers]\n",
    "    byline_cs = [1 if speaker == d['byline'] else 0 for speaker in speakers]\n",
    "    return speakers, comments, host_cs, byline_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers = []\n",
    "comments = []\n",
    "host_cs = []\n",
    "byline_cs = []\n",
    "titles = []\n",
    "\n",
    "for ik, story in enumerate(npr_raw2['text']):\n",
    "    spkrs, cmmnts, hst_cs, bylne_cs = cat_npr_text(story, npr_raw2.loc[ik, 'title'])\n",
    "    titles = titles + [npr_raw2.loc[ik, 'title'] for im in range(len(spkrs))]\n",
    "    speakers = speakers+spkrs\n",
    "    comments = comments +cmmnts\n",
    "    host_cs = host_cs + hst_cs\n",
    "    byline_cs = byline_cs +bylne_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr_df = pd.DataFrame({'speaker': speakers, 'comment':comments, 'host': host_cs, 'byline':byline_cs, 'title': titles})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of reporter names\n",
    "reporters = [name.split()[1].upper() for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows that correspond to other speakers\n",
    "culled_npr = npr_df[npr_df['speaker'].isin(reporters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create blocks of concatenated comments from the correspondent in the given piece\n",
    "\n",
    "# remove host dialogue\n",
    "grps_title = culled_npr[culled_npr.host != 1].groupby('title')\n",
    "\n",
    "speakers = []\n",
    "speaker_texts =[]\n",
    "titles = []\n",
    "ids = []\n",
    "\n",
    "for ik, grp in enumerate(grps_title):\n",
    "    title = grp[0]\n",
    "    grps_speaker = grp[1].groupby('speaker')\n",
    "    for grp2 in grps_speaker:\n",
    "        speaker_text = speaker_texts.append(' '.join(grp2[1].comment))\n",
    "        speakers.append(grp2[0])\n",
    "        titles.append(title)\n",
    "        ids.append(grp2[0]+str(ik))\n",
    "        \n",
    "npr_bystory_df = pd.DataFrame({'ids': ids, 'speaker':speakers, 'comment_text':speaker_texts, 'title':titles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr_bystory_df = pd.read_csv('npr_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRUMFIEL 166\n",
      "BURNETT 440\n",
      "ELVING 280\n",
      "GONZALES 293\n",
      "HAMILTON 361\n",
      "HARRIS 479\n",
      "HORSLEY 744\n",
      "JOYCE 399\n",
      "KEITH 709\n",
      "KODJAK 128\n",
      "LUCAS 108\n",
      "LUDDEN 333\n",
      "MARTIN 186\n",
      "MCCAMMON 237\n",
      "MONTANARO 152\n",
      "NEIGHMOND 255\n",
      "NOGUCHI 446\n",
      "REEVES 605\n",
      "SHAHANI 199\n",
      "SHAPIRO 638\n",
      "STEIN 224\n",
      "WERTHEIMER 266\n"
     ]
    }
   ],
   "source": [
    "# Group news pieces by speaker\n",
    "grps = npr_bystory_df[npr_bystory_df['speaker'].isin(reporters)].groupby('speaker')\n",
    "\n",
    "# A list of the speakers who have more than sample_size articles\n",
    "full_article_speakers = []\n",
    "\n",
    "sample_size = 100\n",
    "culled_npr_bystory = []\n",
    "for grp in grps:\n",
    "    if len(grp[1])>sample_size:\n",
    "        culled_npr_bystory.append(grp[1])#.sample(n=sample_size))\n",
    "        print(grp[0], len(grp[1]))\n",
    "        full_article_speakers.append(grp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe of sample_size number of articles for each reporter\n",
    "culled_npr_bystory_df = pd.concat(culled_npr_bystory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text: remove punctuation, stop words, numbers, and lemmatize remaining tokens\n",
    "def clean_text(text, **kwargs):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    if ('no_stop_words' in kwargs) and (kwargs['no_stop_words'] == True):\n",
    "        allwords = [str(token.lemma_).translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                  and not token.is_stop\n",
    "                  and token.is_alpha]\n",
    "    else:\n",
    "        allwords = [str(token.lemma_).translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                  and token.is_alpha]\n",
    "    \n",
    "    return ' '.join(allwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "culled_npr_bystory_df['cleaned_text'] = [clean_text(nlp(text), no_stop_words = True) for text in culled_npr_bystory_df.comment_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "culled_npr_bystory_df.to_csv('npr_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
