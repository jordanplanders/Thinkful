{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_script(script):\n",
    "    script = script.lstrip('<pre>').split('\\nTHE END')[0]\n",
    "    script = script.replace('McGARRY', 'MCGARRY')\n",
    "    script = script.replace('CUT TO:\\n\\n', 'CUT TO: ')\n",
    "    script_ = re.sub(r'([A-Z])(\\nCUT TO:)', r'\\1\\n\\2',  script)\n",
    "    script = script_.replace('FADE OUT.\\nEND', '')\n",
    "    script = script_.replace('FADE OUT.\\n\\nEND ', '')\n",
    "    script = script.rstrip('\\n')\n",
    "     \n",
    "    return script#' '.join([act.split('\\n\\n',1)[1] for act in script.split('ACT ')[1:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_script_df(script, episode_num):\n",
    "    bits = script.split('\\n\\n')\n",
    "    return pd.DataFrame({'elements':bits, 'episode': [episode_num for ik in range(len(bits))]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_stage_dir(script_df):\n",
    "    stage_dir = []\n",
    "    for ik, bit in enumerate(script_df.elements):\n",
    "        if (bit.split('\\n')[0].isupper() == False) and ('[' not in bit.split('\\n')[0]):\n",
    "            stage_dir.append(1)\n",
    "            script_df.loc[ik, 'elements'] = bit.replace('\\n', ' ')\n",
    "        else:\n",
    "            stage_dir.append(0)\n",
    "            \n",
    "    script_df['stage_dir'] = stage_dir\n",
    "    return script_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_scene_set(script_df):\n",
    "    scene_set = []\n",
    "    for elem in script_df.elements:\n",
    "        lines = elem.split('\\n')\n",
    "        if ('-' in lines[0]) and (lines[0].isupper()):\n",
    "            scene_set.append(1)\n",
    "        else:\n",
    "            scene_set.append(0)\n",
    "\n",
    "    script_df['scene_set'] = scene_set\n",
    "    return script_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def parse_lines_characters(script_df):\n",
    "    line = []\n",
    "    character = []\n",
    "    deliv_dir = []\n",
    "    audio_dir = []\n",
    "\n",
    "    for ik in range(len(script_df.elements)):\n",
    "        if (script_df.iloc[ik]['scene_set'] == 0) and (script_df.iloc[ik]['stage_dir'] == 0):\n",
    "            tmp_elem  = script_df.iloc[ik]['elements'].split('\\n')\n",
    "            \n",
    "            if len(tmp_elem)>1:\n",
    "                # character name & audio delivery notes\n",
    "                tmp_audio_dir = tmp_elem[0].split(' [')\n",
    "                if len(tmp_audio_dir)>1:\n",
    "                    audio_dir.append(tmp_audio_dir[1].strip(']'))\n",
    "                    character.append(tmp_audio_dir[0])\n",
    "                else:\n",
    "                    if (tmp_audio_dir[0].isupper() == True):\n",
    "                        audio_dir.append(np.nan)\n",
    "                        character.append(tmp_audio_dir[0])\n",
    "                    else:\n",
    "                        character.append(' ')\n",
    "                        audio_dir.append(np.nan)\n",
    "\n",
    "                # line & acting delivery notes\n",
    "                tmp_deliv_dir = tmp_elem[1].split('] ')\n",
    "                if len(tmp_deliv_dir)>1:\n",
    "                    deliv_dir.append(tmp_deliv_dir[0].strip('['))\n",
    "                    line.append(tmp_deliv_dir[1])\n",
    "                else:\n",
    "                    line.append(tmp_deliv_dir[0])\n",
    "                    deliv_dir.append(np.nan)\n",
    "            else:\n",
    "                line.append(np.nan)\n",
    "                character.append('Drop')\n",
    "                deliv_dir.append(np.nan)\n",
    "                audio_dir.append(np.nan)\n",
    "\n",
    "        else:\n",
    "            line.append(np.nan)\n",
    "            character.append(' ')\n",
    "            deliv_dir.append(np.nan)\n",
    "            audio_dir.append(np.nan)\n",
    "\n",
    "    script_df['line'] = line\n",
    "    script_df['character'] = character\n",
    "    script_df['deliv_dir'] = deliv_dir\n",
    "    script_df['audio_dir'] = audio_dir\n",
    "    \n",
    "    return script_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load scraped scripts\n",
    "ww_nonSorkin_df = pd.read_json('WW_nonSorkin.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull apart scripts\n",
    "script_dfs= [parse_lines_characters(parse_scene_set(parse_stage_dir(make_script_df(clean_script(text),ik+1)))) for ik, text in enumerate(ww_nonSorkin_df.text)]\n",
    "\n",
    "# concatenate scripts\n",
    "ww_nonSorkin_dfs = pd.concat(script_dfs, axis=0, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with character names that aren't characters\n",
    "for char in [' ', 'DISSOLVE TO', 'FADE OUT.', 'SMASH CUT TO: MAIN TITLES.', 'THE WEST WING', 'ACT ONE', 'ACT TWO', 'END TEASER', 'Drop']:\n",
    "    ww_nonSorkin_dfs = ww_nonSorkin_dfs[~ww_nonSorkin_dfs['character'].str.contains( char)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww_nonSorkin_dfs['label'] = ['NOT!' for ik in range(len(ww_nonSorkin_dfs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load scraped scripts\n",
    "ww_df = pd.read_json('WW.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull apart scripts\n",
    "script_dfs= [parse_lines_characters(parse_scene_set(parse_stage_dir(make_script_df(clean_script(text),ik+1)))) for ik, text in enumerate(ww_df.text)]\n",
    "\n",
    "# concatenate scripts\n",
    "ww_dfs = pd.concat(script_dfs, axis=0, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with character names that aren't characters\n",
    "for char in [' ', 'DISSOLVE TO', 'FADE OUT.', 'SMASH CUT TO: MAIN TITLES.', 'THE WEST WING', 'ACT ONE', 'ACT TWO', 'END TEASER', 'Drop']:\n",
    "    ww_dfs = ww_dfs[~ww_dfs['character'].str.contains( char)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww_dfs['label'] = ['SORKIN' for ik in range(len(ww_dfs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww_sub_dfs = ww_dfs.sample(n = len(ww_nonSorkin_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww_SnS_dfs = pd.concat([ww_nonSorkin_dfs,ww_sub_dfs], axis=0, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(5000)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonwords = []\n",
    "\n",
    "for label in ['Sorkin','NOT!'] :\n",
    "    _text = ' '.join(ww_SnS_dfs['line'][ww_SnS_dfs.label == label])\n",
    "    _words = bag_of_words(nlp(_text))\n",
    "    commonwords = list(set(commonwords+_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = [[nlp(ww_SnS_dfs.iloc[ik]['line']), ww_SnS_dfs.iloc[ik]['label']] for ik in range(len(ww_SnS_dfs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_df = pd.DataFrame(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "\n",
    "# POS dict\n",
    "pos_d = {'VERB':'verb_ct', 'NOUN':'noun_ct', 'ADV':'adv_ct', 'ADP':'adp_ct', \n",
    "         'PROPN':'propn_ct', 'ADJ':'adj_ct', 'DET':'det_ct', 'PUNCT':'punct_ct'}\n",
    "\n",
    "def bow_features(quotes, common_words, **kwargs):\n",
    "    print(len(quotes))\n",
    "#     df2 = {'line': [sentence[0] for sentence in sentences], 'character': [sentence[1] for sentence in sentences]}\n",
    "    \n",
    "    # sentence stats\n",
    "    sent_stats = ['comma_ct', 'word_ct', 'adv_ct', 'adp_ct', 'propn_ct', 'adj_ct', 'punct_ct'] #'verb_ct', 'noun_ct','det_ct',\n",
    "    if 'sent_stats' in kwargs:\n",
    "        df = pd.DataFrame(columns=list(common_words) + sent_stats)\n",
    "        cols = list(common_words)+sent_stats\n",
    "#         df.loc[:, sent_stats] = 0\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=common_words)\n",
    "        cols = list(common_words)\n",
    "    \n",
    "    df.loc[:, common_words] = 0\n",
    "    for col in df.columns:\n",
    "        df[col] = np.zeros(len(quotes[0]))\n",
    "    df['line'] = quotes[0] \n",
    "    df['character'] = quotes[1]\n",
    "    \n",
    "    print('made it to the loop')\n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, quote in enumerate(df['line']):\n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in quote\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            try:\n",
    "                df.loc[i, word] += 1\n",
    "            except:\n",
    "                print(words)\n",
    "        \n",
    "        # add sentence features\n",
    "        if 'sent_stats' in kwargs:\n",
    "            commas = 0\n",
    "            for token in quote:\n",
    "                if token.orth_ == ',':\n",
    "                    commas += 1\n",
    "            df.loc[i, 'comma_ct'] = commas\n",
    "                    \n",
    "            c = Counter([token.pos_ for token in quote])\n",
    "            for key in pos_d.keys():\n",
    "                if key in c.keys():\n",
    "                    df.loc[i, pos_d[key]] = c[key]\n",
    "                else:\n",
    "                    df.loc[i, pos_d[key]] = c[key]\n",
    "            \n",
    "            df.loc[i, 'word_ct'] = len([token for token in quote if (not token.is_punct)])\n",
    "\n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8128\n",
      "made it to the loop\n",
      "Processing row 0\n",
      "['the', 'line']\n",
      "['want', 'line', 'drink']\n",
      "Processing row 1000\n",
      "Processing row 2000\n",
      "['the', 'report', 'administration', 'view', 'that', 'be', 'line', 'what']\n",
      "['so', 'award', 'roll', 'that', 'will', 'line']\n",
      "['-PRON-', 'give', 'line', 'say']\n",
      "['-PRON-', 'when', '-PRON-', 'line', 'be']\n",
      "['-PRON-', 'wife', 'budget', '-PRON-', 'be', 'line', 'do', 'not', 'word']\n",
      "['-PRON-', 'take', 'russell', 'job', 'this', 'not', 'line', 'none']\n",
      "['and', 'hold', 'line', 'make', 'day', 'story']\n",
      "Processing row 3000\n",
      "Processing row 4000\n",
      "['in', 'red', 'line', 'sir']\n",
      "['-PRON-', 'read', 'line']\n",
      "Processing row 5000\n",
      "['-PRON-', 'be', 'residence', 'secure', 'phone', 'line']\n",
      "Processing row 6000\n",
      "['everybody', 'line', 'only', 'drink']\n",
      "['just', 'stuff', '-PRON-', 'panic', 'line']\n",
      "Processing row 7000\n",
      "['then', 'maybe', 'line']\n",
      "Processing row 8000\n"
     ]
    }
   ],
   "source": [
    "word_counts2 = bow_features(quotes_df, words, sent_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 400)"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119ec05c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# cts, ints, patches = plt.hist(word_counts2.iloc[:, ~word_counts2.columns.isin(['character', 'line'])].sum(axis=0), bins = 500)\n",
    "cts, ints, patches = plt.hist(word_counts2['comma_ct'], bins = 500)\n",
    "\n",
    "\n",
    "plt.xlim([0, 400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = word_counts2['character']\n",
    "X = word_counts2.iloc[:, ~word_counts2.columns.isin(['character','line'])]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5689, 1761) (5689,)\n",
      "Training set score: 0.7222710493935666\n",
      "\n",
      "Test set score: 0.6277162771627717\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>character</th>\n",
       "      <th>NOT!</th>\n",
       "      <th>SORKIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NOT!</th>\n",
       "      <td>724</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SORKIN</th>\n",
       "      <td>479</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "character  NOT!  SORKIN\n",
       "row_0                  \n",
       "NOT!        724     429\n",
       "SORKIN      479     807"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))\n",
    "\n",
    "y_pred = train.predict(X_test)\n",
    "pd.crosstab(y_pred, y_test, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5067650676506765"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test[y_test == 'SORKIN'])/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
