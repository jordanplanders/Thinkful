{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler, Bucketizer\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, Word2Vec\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.sql.functions import isnan, when, count, col\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Spark Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_NAME = \"Amazon review sentiment analysis\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "TRAINING_DATA_RATIO = .75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"reviews_Home_and_Kitchen_5.json\"\n",
    "reviewsDF = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsDF_1 = reviewsDF.withColumn(\"total_votes\", reviewsDF.helpful[1])\n",
    "reviewsDF_2 = reviewsDF_1.withColumn(\"perc_helpful\", reviewsDF_1.helpful[0]/reviewsDF_1.helpful[1])\n",
    "\n",
    "reviewsDF_2 = reviewsDF_2.fillna(0, subset=['perc_helpful'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+--------------------+-----------+-------------+---------------+----------+--------------+-----------+------------+\n",
      "|      asin|helpful|overall|          reviewText| reviewTime|   reviewerID|   reviewerName|   summary|unixReviewTime|total_votes|perc_helpful|\n",
      "+----------+-------+-------+--------------------+-----------+-------------+---------------+----------+--------------+-----------+------------+\n",
      "|0615391206| [0, 0]|    5.0|My daughter wante...|10 19, 2013|APYOBQE6M18AA|Martin Schwartz|Best Price|    1382140800|          0|         0.0|\n",
      "+----------+-------+-------+--------------------+-----------+-------------+---------------+----------+--------------+-----------+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviewsDF_2.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----------+----------+----------+------------+-------+--------------+-----------+------------+\n",
      "|asin|overall|reviewText|reviewTime|reviewerID|reviewerName|summary|unixReviewTime|total_votes|perc_helpful|\n",
      "+----+-------+----------+----------+----------+------------+-------+--------------+-----------+------------+\n",
      "|   0|      0|         0|         0|         0|           0|      0|             0|          0|           0|\n",
      "+----+-------+----------+----------+----------+------------+-------+--------------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for null values\n",
    "reviewsDF_2.select([count(when(isnan(c), c)).alias(c) for c in reviewsDF_2.columns if c not in ['helpful']]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [-float(\"inf\"), 3.5, float(\"inf\")]\n",
    "bucketizer = Bucketizer(splits=splits, inputCol=\"overall\", outputCol=\"label\")\n",
    "\n",
    "# Transform original data into its bucket index.\n",
    "reviewsDF_3 = bucketizer.transform(reviewsDF_2)\n",
    "\n",
    "# label_stringIdx = StringIndexer(inputCol = \"binned_overall\", outputCol = \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = reviewsDF_3.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Modeling Pipeline with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n",
    "idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5)\n",
    "\n",
    "# featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2Vec = Word2Vec(vectorSize=200, seed=42, inputCol=\"words\", outputCol=\"w2v_vector\")\n",
    "\n",
    "featureIndexer = VectorIndexer(inputCol=\"w2v_vector\", outputCol=\"features\", maxCategories=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF & Log. Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pipeline.\n",
    "tfidf_pipeline = Pipeline(stages=[tokenizer, hashtf, idf, lr])\n",
    "\n",
    "# Train model.\n",
    "model_tfidf_lr = tfidf_pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions_tfidf_lr = model_tfidf_lr.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8446755776513086 blind guess percentage: 0.824956571669465\n"
     ]
    }
   ],
   "source": [
    "accuracy = predictions_tfidf_lr.filter(predictions_tfidf_lr.label == predictions_tfidf_lr.prediction).count() / float(test_df.count())\n",
    "blind_guess = predictions_tfidf_lr.filter(predictions_tfidf_lr.label == 1).count()/float(test_df.count())\n",
    "print('accuracy:', accuracy, 'blind guess percentage:', blind_guess) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that the model isn't guessing one class exclusively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec and Log Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pipeline\n",
    "w2v_pipeline = Pipeline(stages=[tokenizer, word2Vec, featureIndexer, lr])\n",
    "\n",
    "# Train model.\n",
    "model_d2v_lr = w2v_pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions_d2v_lr = model_d2v_lr.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = predictions_d2v_lr.filter(predictions_d2v_lr.label == predictions_d2v_lr.prediction).count() / float(test_df.count())\n",
    "blind_guess = predictions_d2v_lr.filter(predictions_d2v_lr.label == 1).count()/float(test_df.count())\n",
    "print('accuracy:', accuracy, 'blind guess percentage:', blind_guess) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions_d2v_lr)\n",
    "\n",
    "print(f\"Test Error = {(1.0 - accuracy):g}\")\n",
    "print(f\"Accuracy = {accuracy:g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
